FROM nvidia/cuda:12.3.2-cudnn9-devel-ubuntu22.04

WORKDIR /app

# install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        git \
        build-essential \
        ffmpeg \
        curl \
        python3.10 \
        python3-pip \
        gcc \
        wget \
        ocl-icd-opencl-dev \
        opencl-headers \
        clinfo \
        libclblast-dev \
        libopenblas-dev && \
    apt-mark hold python3.10 && \
    mkdir -p /etc/OpenCL/vendors && \
    echo "libnvidia-opencl.so.1" > /etc/OpenCL/vendors/nvidia.icd && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*
    
# build wheels for llama-cpp-python
RUN pip install --upgrade pip pytest cmake scikit-build setuptools && \
    CMAKE_ARGS="-DGGML_CUDA=on -DCMAKE_CUDA_ARCHITECTURES=75;86;89" pip install llama-cpp-python==0.3.7 --no-cache-dir

# download models
RUN mkdir -p /app/models/mistral_7b \
    /app/models/deepseek_14b \
    /app/models/faster-whisper-small \
    /app/models/faster-whisper-small-sg \
    /app/models/faster-whisper-medium && \

    curl -L -o /app/models/mistral_7b/model.bin "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q6_K.gguf" && \

    curl -L -o /app/models/deepseek_14b/model.bin "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-14B-Q4_K.gguf" && \

    curl -L -o /app/models/faster-whisper-small/config.json "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-small/model.bin "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-small/tokenizer.json "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/tokenizer.json" && \
    curl -L -o /app/models/faster-whisper-small/vocabulary.txt "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/vocabulary.txt" && \

    curl -L -o /app/models/faster-whisper-small-sg/added_tokens.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/added_tokens.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/merges.txt "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/merges.txt" && \
    curl -L -o /app/models/faster-whisper-small-sg/model.bin "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-small-sg/normalizer.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/normalizer.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/preprocessor_config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/preprocessor_config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/special_tokens_map.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/special_tokens_map.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/tokenizer_config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/tokenizer_config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/vocab.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/vocab.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/vocabulary.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/vocabulary.json" && \

    curl -L -o /app/models/faster-whisper-medium/config.json "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-medium/model.bin "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-medium/tokenizer.json "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/tokenizer.json" && \
    curl -L -o /app/models/faster-whisper-medium/vocabulary.txt "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/vocabulary.txt" && \
    
    apt-get clean && rm -rf /var/lib/apt/lists/*

# install Python dependencies
COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt

# copy application code to container
COPY . .

EXPOSE 8000

# run FastAPI Application
CMD [ "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]