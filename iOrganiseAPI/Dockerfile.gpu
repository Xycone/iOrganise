FROM python:3.10-slim

WORKDIR /app

# install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        git \
        build-essential \
        cmake \
        dpkg \
        ffmpeg \
        curl && \
    rm -rf /var/lib/apt/lists/*

# install CUDA & CUDNN
RUN apt-get update && \
    apt-get install -y --no-install-recommends gnupg2 ca-certificates && \
    curl -fsSLO https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb && \
    dpkg -i cuda-keyring_1.0-1_all.deb && \
    rm -rf /var/lib/apt/lists/*

ENV CUDA_VERSION=12.2.0

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    cuda-cudart-12-2=12.2.53-1 \
    cuda-compat-12-2 && \
    rm -rf /var/lib/apt/lists/*

RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf

ENV PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:$PATH
ENV LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    cuda-libraries-12-2=12.2.0-1 \
    libnpp-12-2=12.1.1.14-1 \
    cuda-nvtx-12-2=12.2.53-1 \
    libcusparse-12-2=12.1.1.53-1 \
    libcublas-12-2=12.2.1.16-1 && \
    rm -rf /var/lib/apt/lists/*

RUN apt-mark hold libcublas-12-2

ENV NVIDIA_PRODUCT_NAME=CUDA

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    cuda-cudart-dev-12-2=12.2.53-1 \
    cuda-command-line-tools-12-2=12.2.0-1 \
    cuda-minimal-build-12-2=12.2.0-1 \
    cuda-libraries-dev-12-2=12.2.0-1 \
    cuda-nvml-dev-12-2=12.2.81-1 \
    cuda-nvprof-12-2=12.2.60-1 \
    libnpp-dev-12-2=12.1.1.14-1 \
    libcusparse-dev-12-2=12.1.1.53-1 \
    libcublas-dev-12-2=12.2.1.16-1 \
    cuda-nsight-compute-12-2=12.2.0-1 && \
    rm -rf /var/lib/apt/lists/*

RUN apt-mark hold libcublas-dev-12-2

ENV LIBRARY_PATH=/usr/local/cuda/lib64/stubs

# install Github packages
RUN pip install "git+https://github.com/m-bain/whisperx.git"

# download models
RUN mkdir -p /app/models

RUN mkdir -p /app/models/mistral_7b && \
    curl -L -o /app/models/mistral_7b/model.bin "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q6_K.gguf" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/deepseek_14b && \
    curl -L -o /app/models/deepseek_14b/model.bin "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-14B-Q6_K_L.gguf" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/faster-whisper-small && \
    curl -L -o /app/models/faster-whisper-small/config.json "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-small/model.bin "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-small/tokenizer.json "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/tokenizer.json" && \
    curl -L -o /app/models/faster-whisper-small/vocabulary.txt "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/vocabulary.txt" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/faster-whisper-small-sg && \
    curl -L -o /app/models/faster-whisper-small-sg/added_tokens.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/added_tokens.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/merges.txt "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/merges.txt" && \
    curl -L -o /app/models/faster-whisper-small-sg/model.bin "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-small-sg/normalizer.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/normalizer.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/preprocessor_config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/preprocessor_config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/special_tokens_map.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/special_tokens_map.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/tokenizer_config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/tokenizer_config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/vocab.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/vocab.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/vocabulary.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/vocabulary.json" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/faster-whisper-medium && \
    curl -L -o /app/models/faster-whisper-medium/config.json "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-medium/model.bin "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-medium/tokenizer.json "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/tokenizer.json" && \
    curl -L -o /app/models/faster-whisper-medium/vocabulary.txt "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/vocabulary.txt" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# install Python dependencies
RUN CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python==0.3.7 --no-cache-dir

COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt

# copy application code to container
COPY . .

EXPOSE 8000

# run FastAPI Application
CMD [ "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]