FROM ubuntu:22.04

WORKDIR /app

# install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        git \
        build-essential \
        ffmpeg \
        curl \
        python3.10 \
        python3-pip && \ 
    apt-mark hold python3.10 && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# download models
RUN mkdir -p /app/models

RUN mkdir -p /app/models/mistral_7b && \
    curl -L -o /app/models/mistral_7b/model.bin "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q6_K.gguf" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/deepseek_14b && \
    curl -L -o /app/models/deepseek_14b/model.bin "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-14B-Q6_K_L.gguf" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/faster-whisper-small && \
    curl -L -o /app/models/faster-whisper-small/config.json "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-small/model.bin "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-small/tokenizer.json "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/tokenizer.json" && \
    curl -L -o /app/models/faster-whisper-small/vocabulary.txt "https://huggingface.co/guillaumekln/faster-whisper-small/resolve/main/vocabulary.txt" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/faster-whisper-small-sg && \
    curl -L -o /app/models/faster-whisper-small-sg/added_tokens.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/added_tokens.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/merges.txt "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/merges.txt" && \
    curl -L -o /app/models/faster-whisper-small-sg/model.bin "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-small-sg/normalizer.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/normalizer.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/preprocessor_config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/preprocessor_config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/special_tokens_map.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/special_tokens_map.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/tokenizer_config.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/tokenizer_config.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/vocab.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/vocab.json" && \
    curl -L -o /app/models/faster-whisper-small-sg/vocabulary.json "https://huggingface.co/Xycone/faster-whisper-SGspeech-finetune/resolve/main/vocabulary.json" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN mkdir -p /app/models/faster-whisper-medium && \
    curl -L -o /app/models/faster-whisper-medium/config.json "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/config.json" && \
    curl -L -o /app/models/faster-whisper-medium/model.bin "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/model.bin" && \
    curl -L -o /app/models/faster-whisper-medium/tokenizer.json "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/tokenizer.json" && \
    curl -L -o /app/models/faster-whisper-medium/vocabulary.txt "https://huggingface.co/guillaumekln/faster-whisper-medium/resolve/main/vocabulary.txt" && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# install Python dependencies
RUN pip install pytest cmake scikit-build setuptools && \
    pip install llama-cpp-python==0.3.7 --no-cache-dir

COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt

# copy application code to container
COPY . .

EXPOSE 8000

# run FastAPI Application
CMD [ "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]